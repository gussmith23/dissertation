\chapter*{\Cref{part:lakeroad} Abstract}

In \cref{part:lakeroad} of this dissertation,
  I apply my thesis
  to a fully separate domain:
  \textit{hardware} compilers.
I clearly demonstrate
  how a component of hardware compilers
  called a \textit{technology mapper}
  can be automatically generated
  using widely-available
  (\cref{thesis:ubiquity})
  simulation
  and verification models
  of the hardware platform
  the compiler targets.
Furthermore,
  I show how these automatically-generated
  technology mappers
  are more correct
  (\cref{thesis:correctness}),
  more complete
  (\cref{thesis:optimizations}),
  and more extensible
  (\cref{thesis:devtime}).

\hl{i moved this up here. is it weird to have these two paragraphs next to each other?}
FPGA technology mapping is the process of
  implementing a hardware design expressed in 
  high-level HDL (hardware design language) code
  using the low-level, architecture-specific primitives of 
  the target FPGA.
As FPGAs become increasingly heterogeneous, 
  achieving high performance
  requires hardware synthesis tools 
  that better support mapping to complex, 
  highly configurable primitives 
  like digital signal processors (DSPs).
Current tools
  support DSP mapping via handwritten special-case mapping rules,
  which are laborious to write, error-prone, and often overlook mapping opportunities.
In \cref{part:lakeroad} of this dissertation,
  we introduce \lr,
  a principled approach to technology mapping via
  sketch-guided program synthesis.
\lr leverages two techniques---architecture-independent 
  sketch templates and semantics extraction from HDL---to
  provide extensible (\labelcref{thesis:devtime})
  technology mapping 
  with stronger correctness guarantees
  (\labelcref{thesis:correctness})
  and higher coverage of 
  % micro-design 
  mapping opportunities
  (\labelcref{thesis:optimizations})
  than state-of-the-art tools.
Across representative microbenchmarks,
  \lr produces
  2--3.5$\times$ the number of optimal mappings
  compared to proprietary state-of-the-art tools
  and
  6--44$\times$ the number of optimal mappings
  compared to popular open-source tools,
  while also providing correctness guarantees
  not given by any other tool.